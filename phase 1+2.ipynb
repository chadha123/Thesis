{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# baseline experiment"
      ],
      "metadata": {
        "id": "zc1j081GkbWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U diffusers transformers huggingface_hub accelerate sentencepiece"
      ],
      "metadata": {
        "id": "33-2LphreCJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUjXN3HgdRAS"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "ROOT = \"/content/drive/MyDrive/thesis2\"\n",
        "\n",
        "\n",
        "HF_CACHE_DIR = f\"{ROOT}/sd35_cache\"\n",
        "os.makedirs(HF_CACHE_DIR, exist_ok=True)\n",
        "\n",
        "# Phase 1: smile experiment folders\n",
        "PHASE_ROOT = f\"{ROOT}/phase1_smile\"\n",
        "IMG_ROOT = f\"{PHASE_ROOT}/images\"\n",
        "LOG_ROOT = f\"{PHASE_ROOT}/logs\"\n",
        "\n",
        "os.makedirs(IMG_ROOT, exist_ok=True)\n",
        "os.makedirs(LOG_ROOT, exist_ok=True)\n",
        "\n",
        "os.environ[\"HF_HOME\"] = HF_CACHE_DIR\n",
        "os.environ[\"HF_HUB_CACHE\"] = HF_CACHE_DIR\n",
        "\n",
        "print(\"HF cache:\", HF_CACHE_DIR)\n",
        "print(\"Phase 1 images:\", IMG_ROOT)\n",
        "print(\"Phase 1 logs:\", LOG_ROOT)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U diffusers transformers huggingface_hub accelerate sentencepiece\n",
        "\n",
        "from huggingface_hub import login\n",
        "from diffusers import StableDiffusion3Pipeline\n",
        "import torch\n",
        "\n",
        "\n",
        "\n",
        "model_id = \"stabilityai/stable-diffusion-3.5-medium\"\n",
        "\n",
        "pipe = StableDiffusion3Pipeline.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.float16,\n",
        "    token=HF_TOKEN,\n",
        ")\n",
        "\n",
        "pipe = pipe.to(\"cuda\")\n",
        "pipe.enable_attention_slicing()\n",
        "\n",
        "print(\"Loaded on:\", torch.cuda.get_device_name(0))\n"
      ],
      "metadata": {
        "id": "7bCjGWUgdcBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Prompts for Phase 1: neutral / smile ===\n",
        "BASE_FACE_PROMPT = (\n",
        "    \"a photorealistic portrait of a human face, studio lighting, \"\n",
        "    \"high resolution, natural skin texture, realistic anatomy, \"\n",
        "    \"professional photography, symmetric face, looking forward\"\n",
        ")\n",
        "\n",
        "CONDITIONS = {\n",
        "    \"neutral\": {\n",
        "        \"prompt\": BASE_FACE_PROMPT\n",
        "        + \", neutral expression, no smile, relaxed mouth, closed lips\",\n",
        "    },\n",
        "    \"smiling\": {\n",
        "        \"prompt\": BASE_FACE_PROMPT\n",
        "        + \", smiling, visible teeth, joyful expression, warm smile\",\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "N_VARIANTS = 30       # images per condition\n",
        "BASE_SEED = 123\n",
        "HEIGHT = 768\n",
        "WIDTH = 768\n",
        "NUM_STEPS = 30\n",
        "GUIDANCE_SCALE = 7.0\n"
      ],
      "metadata": {
        "id": "laPsl3vfdhoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import csv\n",
        "from datetime import datetime\n",
        "\n",
        "def get_condition_paths(condition_name: str):\n",
        "    cond_img_dir = os.path.join(IMG_ROOT, condition_name)\n",
        "    cond_log_path = os.path.join(LOG_ROOT, f\"seed_diversity_{condition_name}.csv\")\n",
        "    os.makedirs(cond_img_dir, exist_ok=True)\n",
        "    return cond_img_dir, cond_log_path\n",
        "\n",
        "def generate_seed_diversity_for_condition(\n",
        "    condition_name: str,\n",
        "    n_variants: int = N_VARIANTS,\n",
        "    base_seed: int = BASE_SEED,\n",
        "    num_inference_steps: int = NUM_STEPS,\n",
        "    guidance_scale: float = GUIDANCE_SCALE,\n",
        "    height: int = HEIGHT,\n",
        "    width: int = WIDTH,\n",
        "):\n",
        "    assert condition_name in CONDITIONS, f\"Unknown condition: {condition_name}\"\n",
        "    prompt = CONDITIONS[condition_name][\"prompt\"]\n",
        "\n",
        "    cond_img_dir, cond_log_path = get_condition_paths(condition_name)\n",
        "\n",
        "    # init CSV if needed\n",
        "    if not os.path.exists(cond_log_path):\n",
        "        with open(cond_log_path, \"w\", newline=\"\") as f:\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerow([\n",
        "                \"timestamp\",\n",
        "                \"condition\",\n",
        "                \"prompt\",\n",
        "                \"seed\",\n",
        "                \"num_inference_steps\",\n",
        "                \"guidance_scale\",\n",
        "                \"height\",\n",
        "                \"width\",\n",
        "                \"image_path\",\n",
        "            ])\n",
        "\n",
        "    for i in range(n_variants):\n",
        "        seed = base_seed + i\n",
        "        generator = torch.Generator(device=\"cuda\").manual_seed(seed)\n",
        "\n",
        "        print(f\"[{condition_name}] {i+1}/{n_variants} (seed={seed})\")\n",
        "        image = pipe(\n",
        "            prompt,\n",
        "            num_inference_steps=num_inference_steps,\n",
        "            guidance_scale=guidance_scale,\n",
        "            height=height,\n",
        "            width=width,\n",
        "            generator=generator,\n",
        "        ).images[0]\n",
        "\n",
        "        fname = f\"{condition_name}_seed{seed}.png\"\n",
        "        save_path = os.path.join(cond_img_dir, fname)\n",
        "        image.save(save_path)\n",
        "\n",
        "        with open(cond_log_path, \"a\", newline=\"\") as f:\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerow([\n",
        "                datetime.now().isoformat(timespec=\"seconds\"),\n",
        "                condition_name,\n",
        "                prompt,\n",
        "                seed,\n",
        "                num_inference_steps,\n",
        "                guidance_scale,\n",
        "                height,\n",
        "                width,\n",
        "                save_path,\n",
        "            ])\n",
        "\n",
        "        print(\"  saved:\", save_path)\n",
        "\n",
        "    print(f\" Done for '{condition_name}'. Log at {cond_log_path}\")\n"
      ],
      "metadata": {
        "id": "F_lfSlobfNMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_seed_diversity_for_condition(\"neutral\")\n",
        "generate_seed_diversity_for_condition(\"smiling\")\n"
      ],
      "metadata": {
        "id": "LhoGs_ARfSzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q lpips scikit-image pandas matplotlib seaborn\n"
      ],
      "metadata": {
        "id": "_vvP4Uf_hR81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "import lpips\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "lpips_model = lpips.LPIPS(net='vgg').to(device)\n",
        "lpips_model.eval()\n",
        "\n",
        "def load_image(path, size=None):\n",
        "    img = Image.open(path).convert(\"RGB\")\n",
        "    if size is not None:\n",
        "        img = img.resize(size, Image.BICUBIC)\n",
        "    return img\n",
        "\n",
        "def img_to_numpy(img):\n",
        "    return np.asarray(img).astype(np.float32) / 255.0\n",
        "\n",
        "def img_to_lpips_tensor(img):\n",
        "    arr = np.asarray(img).astype(np.float32) / 255.0\n",
        "    arr = (arr * 2.0) - 1.0\n",
        "    arr = torch.from_numpy(arr).permute(2, 0, 1).unsqueeze(0)\n",
        "    return arr.to(device)\n",
        "\n",
        "def compute_pairwise_metrics_for_condition(condition_name: str):\n",
        "    cond_img_dir, cond_log_path = get_condition_paths(condition_name)\n",
        "    print(f\"\\n=== Metrics for: {condition_name} ===\")\n",
        "    print(\"Images:\", cond_img_dir)\n",
        "    print(\"Log:\", cond_log_path)\n",
        "\n",
        "    df = pd.read_csv(cond_log_path)\n",
        "    df_cond = df[df[\"condition\"] == condition_name].reset_index(drop=True)\n",
        "    print(\"Rows:\", len(df_cond))\n",
        "\n",
        "    images_np, images_lpips, paths_used = [], [], []\n",
        "    target_size = None\n",
        "\n",
        "    for _, row in df_cond.iterrows():\n",
        "        path = row[\"image_path\"]\n",
        "        if not os.path.exists(path):\n",
        "            print(\" missing:\", path)\n",
        "            continue\n",
        "\n",
        "        if target_size is None:\n",
        "            target_size = Image.open(path).convert(\"RGB\").size\n",
        "\n",
        "        img = load_image(path, size=target_size)\n",
        "        images_np.append(img_to_numpy(img))\n",
        "        images_lpips.append(img_to_lpips_tensor(img))\n",
        "        paths_used.append(path)\n",
        "\n",
        "    print(\"Loaded\", len(images_np), \"images of size\", target_size)\n",
        "\n",
        "    results = []\n",
        "    n = len(images_np)\n",
        "\n",
        "    for i in range(n):\n",
        "        for j in range(i+1, n):\n",
        "            seed_i = int(df_cond.loc[i, \"seed\"])\n",
        "            seed_j = int(df_cond.loc[j, \"seed\"])\n",
        "\n",
        "            arr_i, arr_j = images_np[i], images_np[j]\n",
        "\n",
        "            mse_val = float(np.mean((arr_i - arr_j)**2))\n",
        "            ssim_val = float(ssim(arr_i, arr_j, channel_axis=-1, data_range=1.0))\n",
        "            with torch.no_grad():\n",
        "                lpips_val = float(lpips_model(images_lpips[i], images_lpips[j]).item())\n",
        "\n",
        "            results.append({\n",
        "                \"condition\": condition_name,\n",
        "                \"seed_i\": seed_i,\n",
        "                \"seed_j\": seed_j,\n",
        "                \"image_i\": paths_used[i],\n",
        "                \"image_j\": paths_used[j],\n",
        "                \"MSE\": mse_val,\n",
        "                \"SSIM\": ssim_val,\n",
        "                \"LPIPS\": lpips_val,\n",
        "            })\n",
        "\n",
        "            print(f\"{condition_name} ({seed_i},{seed_j}) -> \"\n",
        "                  f\"MSE={mse_val:.5f}, SSIM={ssim_val:.4f}, LPIPS={lpips_val:.4f}\")\n",
        "\n",
        "    metrics_df = pd.DataFrame(results)\n",
        "    pairwise_path = os.path.join(LOG_ROOT, f\"pairwise_{condition_name}.csv\")\n",
        "    metrics_df.to_csv(pairwise_path, index=False)\n",
        "    print(\"saved pairwise to:\", pairwise_path)\n",
        "\n",
        "    # summary\n",
        "    summary = {\n",
        "        \"condition\": condition_name,\n",
        "        \"N_pairs\": len(metrics_df),\n",
        "        \"LPIPS_mean\": metrics_df[\"LPIPS\"].mean(),\n",
        "        \"LPIPS_std\":  metrics_df[\"LPIPS\"].std(),\n",
        "        \"SSIM_mean\":  metrics_df[\"SSIM\"].mean(),\n",
        "        \"SSIM_std\":   metrics_df[\"SSIM\"].std(),\n",
        "        \"MSE_mean\":   metrics_df[\"MSE\"].mean(),\n",
        "        \"MSE_std\":    metrics_df[\"MSE\"].std(),\n",
        "    }\n",
        "    summary_df = pd.DataFrame([summary])\n",
        "    display(summary_df)\n",
        "\n",
        "    summary_path = os.path.join(LOG_ROOT, \"seed_diversity_summary_smile.csv\")\n",
        "    if os.path.exists(summary_path):\n",
        "        old = pd.read_csv(summary_path)\n",
        "        pd.concat([old, summary_df], ignore_index=True).to_csv(summary_path, index=False)\n",
        "    else:\n",
        "        summary_df.to_csv(summary_path, index=False)\n",
        "\n",
        "    print(\"updated summary at:\", summary_path)\n",
        "    return metrics_df, summary_df\n"
      ],
      "metadata": {
        "id": "4YNwja8nhWTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_neutral, summary_neutral = compute_pairwise_metrics_for_condition(\"neutral\")\n",
        "metrics_smiling, summary_smiling = compute_pairwise_metrics_for_condition(\"smiling\")\n"
      ],
      "metadata": {
        "id": "cqToMXvuhfA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# guidance"
      ],
      "metadata": {
        "id": "J5vcdJ7PkmAh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "\n",
        "try:\n",
        "    ROOT\n",
        "except NameError:\n",
        "    ROOT = \"/content/drive/MyDrive/thesis2\"\n",
        "\n",
        "P2_ROOT = f\"{ROOT}/phase2_guidance_faces\"\n",
        "P2_RESULTS_ROOT = f\"{P2_ROOT}/results/faces\"\n",
        "P2_LOG_ROOT = f\"{P2_ROOT}/logs\"\n",
        "\n",
        "os.makedirs(P2_RESULTS_ROOT, exist_ok=True)\n",
        "os.makedirs(P2_LOG_ROOT, exist_ok=True)\n",
        "\n",
        "print(\"Phase 2 root:\", P2_ROOT)\n",
        "print(\"Results root:\", P2_RESULTS_ROOT)\n",
        "print(\"Logs root:\", P2_LOG_ROOT)\n",
        "\n",
        "# Prompts for Phase 2\n",
        "P2_PROMPTS = {\n",
        "    \"neutral\": (\n",
        "          \"a photorealistic portrait of a human face, studio lighting, \"\n",
        "          \"high resolution, natural skin texture, realistic anatomy, \"\n",
        "          \"professional photography, symmetric face, looking forward, \"\n",
        "          \"neutral expression, no smile, relaxed mouth, closed lips\"\n",
        "),\n",
        "    \"smiling\": (\n",
        "        \"a photorealistic portrait of a human face, studio lighting, \"\n",
        "        \"high resolution, natural skin texture, realistic anatomy, \"\n",
        "        \"professional photography, symmetric face, looking forward, \"\n",
        "        \"smiling, visible teeth, joyful expression, warm smile\"\n",
        "    )\n",
        "}\n",
        "\n",
        "P2_GUIDANCE_LEVELS = [1.0, 3.0, 5.0, 7.5, 10.0]\n",
        "P2_N_VARIANTS = 20\n",
        "P2_BASE_SEED = 12345\n",
        "P2_HEIGHT = 768\n",
        "P2_WIDTH = 768\n",
        "P2_NUM_STEPS = 18\n"
      ],
      "metadata": {
        "id": "29mVamRgliUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import csv\n",
        "from datetime import datetime\n",
        "\n",
        "def p2_get_paths(condition: str, guidance: float):\n",
        "    \"\"\"Return (img_dir, log_path) for this condition + guidance.\"\"\"\n",
        "    g_str = str(guidance).replace('.', '_')\n",
        "    img_dir = os.path.join(P2_RESULTS_ROOT, condition, f\"guidance_{g_str}\")\n",
        "    os.makedirs(img_dir, exist_ok=True)\n",
        "\n",
        "    # One log per condition across all guidance\n",
        "    log_path = os.path.join(P2_LOG_ROOT, f\"seed_diversity_{condition}_guidance.csv\")\n",
        "    return img_dir, log_path\n",
        "\n",
        "def p2_generate_for_condition_guidance(\n",
        "    condition: str,\n",
        "    guidance: float,\n",
        "    n_variants: int = P2_N_VARIANTS,\n",
        "    base_seed: int = P2_BASE_SEED,\n",
        "    num_inference_steps: int = P2_NUM_STEPS,\n",
        "    height: int = P2_HEIGHT,\n",
        "    width: int = P2_WIDTH,\n",
        "):\n",
        "    assert condition in P2_PROMPTS, f\"Unknown condition: {condition}\"\n",
        "    prompt = P2_PROMPTS[condition]\n",
        "\n",
        "    img_dir, log_path = p2_get_paths(condition, guidance)\n",
        "\n",
        "    # Create CSV header if needed\n",
        "    if not os.path.exists(log_path):\n",
        "        with open(log_path, \"w\", newline=\"\") as f:\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerow([\n",
        "                \"timestamp\",\n",
        "                \"condition\",\n",
        "                \"prompt\",\n",
        "                \"guidance_scale\",\n",
        "                \"seed\",\n",
        "                \"num_inference_steps\",\n",
        "                \"height\",\n",
        "                \"width\",\n",
        "                \"image_path\",\n",
        "            ])\n",
        "\n",
        "    for i in range(n_variants):\n",
        "        seed = base_seed + i\n",
        "        gen = torch.Generator(device=\"cuda\").manual_seed(seed)\n",
        "\n",
        "        print(f\"[{condition}] guidance={guidance} | {i+1}/{n_variants} (seed={seed})\")\n",
        "        image = pipe(\n",
        "            prompt,\n",
        "            num_inference_steps=num_inference_steps,\n",
        "            guidance_scale=guidance,\n",
        "            height=height,\n",
        "            width=width,\n",
        "            generator=gen,\n",
        "        ).images[0]\n",
        "\n",
        "        g_str = str(guidance).replace('.', '_')\n",
        "        fname = f\"{condition}_g{g_str}_seed{seed}.png\"\n",
        "        save_path = os.path.join(img_dir, fname)\n",
        "        image.save(save_path)\n",
        "\n",
        "        with open(log_path, \"a\", newline=\"\") as f:\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerow([\n",
        "                datetime.now().isoformat(timespec=\"seconds\"),\n",
        "                condition,\n",
        "                prompt,\n",
        "                guidance,\n",
        "                seed,\n",
        "                num_inference_steps,\n",
        "                height,\n",
        "                width,\n",
        "                save_path,\n",
        "            ])\n",
        "\n",
        "        print(\"saved:\", save_path)\n",
        "\n",
        "    print(f\"Done for condition={condition}, guidance={guidance}\")\n"
      ],
      "metadata": {
        "id": "KMqOMXizlk1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for cond in [\"neutral\", \"smiling\"]:\n",
        "    for g in P2_GUIDANCE_LEVELS:\n",
        "        p2_generate_for_condition_guidance(cond, g)\n"
      ],
      "metadata": {
        "id": "6DEGXAuWlnia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "import lpips\n",
        "\n",
        "\n",
        "try:\n",
        "    lpips_model\n",
        "except NameError:\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    lpips_model = lpips.LPIPS(net='vgg').to(device)\n",
        "    lpips_model.eval()\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def p2_load_image(path, size=None):\n",
        "    img = Image.open(path).convert(\"RGB\")\n",
        "    if size is not None:\n",
        "        img = img.resize(size, Image.BICUBIC)\n",
        "    return img\n",
        "\n",
        "def p2_img_to_numpy(img):\n",
        "    return np.asarray(img).astype(np.float32) / 255.0\n",
        "\n",
        "def p2_img_to_lpips_tensor(img):\n",
        "    arr = np.asarray(img).astype(np.float32) / 255.0\n",
        "    arr = (arr * 2.0) - 1.0\n",
        "    arr = torch.from_numpy(arr).permute(2, 0, 1).unsqueeze(0)\n",
        "    return arr.to(device)\n",
        "\n",
        "def p2_compute_pairwise_for(condition: str, guidance: float):\n",
        "    img_dir, log_path = p2_get_paths(condition, guidance)\n",
        "    print(f\"\\n=== {condition} | guidance={guidance} ===\")\n",
        "    print(\"Log:\", log_path)\n",
        "\n",
        "    df = pd.read_csv(log_path)\n",
        "    df_sub = df[(df[\"condition\"] == condition) & (df[\"guidance_scale\"] == guidance)].reset_index(drop=True)\n",
        "    print(\"Rows:\", len(df_sub))\n",
        "\n",
        "    if len(df_sub) < 2:\n",
        "        print(\"Not enough images for pairwise metrics.\")\n",
        "        return None, None\n",
        "\n",
        "    images_np, images_lpips, paths_used = [], [], []\n",
        "    target_size = None\n",
        "\n",
        "    for _, row in df_sub.iterrows():\n",
        "        path = row[\"image_path\"]\n",
        "        if not os.path.exists(path):\n",
        "            print(\"missing:\", path)\n",
        "            continue\n",
        "\n",
        "        if target_size is None:\n",
        "            target_size = Image.open(path).convert(\"RGB\").size\n",
        "\n",
        "        img = p2_load_image(path, size=target_size)\n",
        "        images_np.append(p2_img_to_numpy(img))\n",
        "        images_lpips.append(p2_img_to_lpips_tensor(img))\n",
        "        paths_used.append(path)\n",
        "\n",
        "    print(\"Loaded\", len(images_np), \"images, size:\", target_size)\n",
        "\n",
        "    results = []\n",
        "    n = len(images_np)\n",
        "\n",
        "    for i in range(n):\n",
        "        for j in range(i + 1, n):\n",
        "            seed_i = int(df_sub.loc[i, \"seed\"])\n",
        "            seed_j = int(df_sub.loc[j, \"seed\"])\n",
        "\n",
        "            arr_i, arr_j = images_np[i], images_np[j]\n",
        "\n",
        "            mse_val = float(np.mean((arr_i - arr_j) ** 2))\n",
        "            ssim_val = float(ssim(arr_i, arr_j, channel_axis=-1, data_range=1.0))\n",
        "\n",
        "            with torch.no_grad():\n",
        "                lpips_val = float(lpips_model(images_lpips[i], images_lpips[j]).item())\n",
        "\n",
        "            results.append({\n",
        "                \"condition\": condition,\n",
        "                \"guidance_scale\": guidance,\n",
        "                \"seed_i\": seed_i,\n",
        "                \"seed_j\": seed_j,\n",
        "                \"image_i\": paths_used[i],\n",
        "                \"image_j\": paths_used[j],\n",
        "                \"MSE\": mse_val,\n",
        "                \"SSIM\": ssim_val,\n",
        "                \"LPIPS\": lpips_val,\n",
        "            })\n",
        "\n",
        "    metrics_df = pd.DataFrame(results)\n",
        "\n",
        "    g_str = str(guidance).replace('.', '_')\n",
        "    pairwise_name = f\"seed_diversity_pairwise_{condition}_guidance_{g_str}.csv\"\n",
        "    pairwise_path = os.path.join(P2_LOG_ROOT, pairwise_name)\n",
        "    metrics_df.to_csv(pairwise_path, index=False)\n",
        "    print(\" Saved pairwise metrics to:\", pairwise_path)\n",
        "\n",
        "    summary = {\n",
        "        \"condition\": condition,\n",
        "        \"guidance_scale\": guidance,\n",
        "        \"N_pairs\": len(metrics_df),\n",
        "        \"LPIPS_mean\": metrics_df[\"LPIPS\"].mean(),\n",
        "        \"LPIPS_std\":  metrics_df[\"LPIPS\"].std(),\n",
        "        \"SSIM_mean\":  metrics_df[\"SSIM\"].mean(),\n",
        "        \"SSIM_std\":   metrics_df[\"SSIM\"].std(),\n",
        "        \"MSE_mean\":   metrics_df[\"MSE\"].mean(),\n",
        "        \"MSE_std\":    metrics_df[\"MSE\"].std(),\n",
        "    }\n",
        "    summary_df = pd.DataFrame([summary])\n",
        "    display(summary_df)\n",
        "\n",
        "    return metrics_df, summary_df\n"
      ],
      "metadata": {
        "id": "kfzaMYlQltim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def p2_run_all_metrics_for_condition(condition: str):\n",
        "    all_summary = []\n",
        "    for g in P2_GUIDANCE_LEVELS:\n",
        "        metrics_df, summary_df = p2_compute_pairwise_for(condition, g)\n",
        "        if summary_df is not None:\n",
        "            all_summary.append(summary_df)\n",
        "\n",
        "    if not all_summary:\n",
        "        print(\"No metric summaries for\", condition)\n",
        "        return None\n",
        "\n",
        "    summary_all = pd.concat(all_summary, ignore_index=True)\n",
        "    summary_name = f\"seed_diversity_summary_{condition}_guidance.csv\"\n",
        "    summary_path = os.path.join(P2_LOG_ROOT, summary_name)\n",
        "    summary_all.to_csv(summary_path, index=False)\n",
        "    print(f\"\\nSaved summary for {condition} to:\", summary_path)\n",
        "    display(summary_all)\n",
        "    return summary_all\n",
        "\n",
        "summary_neutral_p2 = p2_run_all_metrics_for_condition(\"neutral\")\n",
        "summary_smiling_p2 = p2_run_all_metrics_for_condition(\"smiling\")\n"
      ],
      "metadata": {
        "id": "mR5OZBpkoe2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def p2_metric_table(summary_df, metric: str, condition: str):\n",
        "    tbl = summary_df[[\"guidance_scale\", f\"{metric}_mean\"]].copy()\n",
        "    tbl = tbl.sort_values(\"guidance_scale\").reset_index(drop=True)\n",
        "    tbl.columns = [\"guidance_scale\", f\"{condition}_{metric}_mean\"]\n",
        "    return tbl\n",
        "\n",
        "lpips_neutral_tbl = p2_metric_table(summary_neutral_p2, \"LPIPS\", \"neutral\")\n",
        "lpips_smiling_tbl = p2_metric_table(summary_smiling_p2, \"LPIPS\", \"smiling\")\n",
        "\n",
        "ssim_neutral_tbl = p2_metric_table(summary_neutral_p2, \"SSIM\", \"neutral\")\n",
        "ssim_smiling_tbl = p2_metric_table(summary_smiling_p2, \"SSIM\", \"smiling\")\n",
        "\n",
        "mse_neutral_tbl = p2_metric_table(summary_neutral_p2, \"MSE\", \"neutral\")\n",
        "mse_smiling_tbl = p2_metric_table(summary_smiling_p2, \"MSE\", \"smiling\")\n",
        "\n",
        "print(\"LPIPS vs guidance:\")\n",
        "display(lpips_neutral_tbl.merge(lpips_smiling_tbl, on=\"guidance_scale\"))\n",
        "\n",
        "print(\"SSIM vs guidance:\")\n",
        "display(ssim_neutral_tbl.merge(ssim_smiling_tbl, on=\"guidance_scale\"))\n",
        "\n",
        "print(\"MSE vs guidance:\")\n",
        "display(mse_neutral_tbl.merge(mse_smiling_tbl, on=\"guidance_scale\"))\n"
      ],
      "metadata": {
        "id": "kBXqdodRox1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "GUIDANCE_LOG_DIR = \"/content/drive/MyDrive/thesis2/phase2_guidance_faces/logs\"\n",
        "\n",
        "# 2) Regex to catch condition + guidance value from filenames like:\n",
        "#     seed_diversity_pairwise_neutral_guidance_1_0.csv\n",
        "pairwise_pattern = re.compile(\n",
        "    r\"seed_diversity_pairwise_(neutral|smiling)_guidance_([0-9_]+)\\.csv\"\n",
        ")\n",
        "\n",
        "rows = []\n",
        "\n",
        "for fname in os.listdir(GUIDANCE_LOG_DIR):\n",
        "    m = pairwise_pattern.match(fname)\n",
        "    if not m:\n",
        "        continue\n",
        "\n",
        "    condition = m.group(1)                 # \"neutral\" or \"smiling\"\n",
        "    g_str = m.group(2)                     # e.g. \"1_0\", \"7_5\", \"10_0\"\n",
        "    guidance = float(g_str.replace(\"_\", \".\"))\n",
        "\n",
        "    fpath = os.path.join(GUIDANCE_LOG_DIR, fname)\n",
        "    df = pd.read_csv(fpath)\n",
        "\n",
        "    # make column names easier to handle\n",
        "    df.columns = [c.lower() for c in df.columns]\n",
        "\n",
        "    # figure out which metrics are present\n",
        "    metric_names = []\n",
        "    for cand in [\"lpips\", \"ssim\", \"mse\", \"clip_cosine_dst\", \"clip_dist\"]:\n",
        "        if cand in df.columns:\n",
        "            metric_names.append(cand)\n",
        "\n",
        "    stats = {\"condition\": condition, \"guidance\": guidance}\n",
        "\n",
        "    for mname in metric_names:\n",
        "        stats[f\"{mname}_mean\"] = df[mname].mean()\n",
        "        stats[f\"{mname}_std\"] = df[mname].std()\n",
        "\n",
        "    rows.append(stats)\n",
        "\n",
        "# 3) Put everything in a DataFrame\n",
        "guidance_summary = pd.DataFrame(rows)\n",
        "\n",
        "# nice ordering\n",
        "guidance_summary = guidance_summary.sort_values(\n",
        "    by=[\"condition\", \"guidance\"]\n",
        ").reset_index(drop=True)\n",
        "\n",
        "guidance_summary\n"
      ],
      "metadata": {
        "id": "NGISHPlEL6KB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}