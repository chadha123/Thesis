{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pJgoHDR4pF8"
      },
      "outputs": [],
      "source": [
        "# --- Core imports ---\n",
        "import os\n",
        "import random\n",
        "\n",
        "import torch\n",
        "from diffusers import StableDiffusion3Pipeline\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Make plots inline\n",
        "%matplotlib inline\n",
        "\n",
        "# --- Paths ---\n",
        "OUT_ROOT = \"/content/drive/MyDrive/thesis2/classifier_dataset\"\n",
        "OUT_NEUTRAL_DIR = os.path.join(OUT_ROOT, \"neutral\")\n",
        "OUT_SMILING_DIR = os.path.join(OUT_ROOT, \"smiling\")\n",
        "METADATA_PATH = os.path.join(OUT_ROOT, \"metadata.csv\")\n",
        "\n",
        "os.makedirs(OUT_NEUTRAL_DIR, exist_ok=True)\n",
        "os.makedirs(OUT_SMILING_DIR, exist_ok=True)\n",
        "\n",
        "# --- Generation settings ---\n",
        "HEIGHT = 768\n",
        "WIDTH = 768\n",
        "NUM_STEPS = 18\n",
        "GUIDANCE_SCALE = 7.0\n",
        "BASE_SEED = 12345   # deterministic base\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "torch.backends.cudnn.benchmark = True  # small speed-up when size is fixed\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "from diffusers import StableDiffusion3Pipeline\n",
        "import torch\n",
        "\n",
        "\n",
        "\n",
        "model_id = \"stabilityai/stable-diffusion-3.5-medium\"\n",
        "\n",
        "pipe = StableDiffusion3Pipeline.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.float16,\n",
        "    token=HF_TOKEN,\n",
        ")\n",
        "\n",
        "pipe = pipe.to(\"cuda\")\n",
        "pipe.enable_attention_slicing()\n",
        "\n",
        "print(\"Loaded SD 3.5 on:\", torch.cuda.get_device_name(0))\n"
      ],
      "metadata": {
        "id": "F7pt3DXY5AY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Base face description\n",
        "BASE_FACE = (\n",
        "    \"a photorealistic portrait of a human face, studio lighting, high resolution, \"\n",
        "    \"natural skin texture, realistic anatomy, professional photography, \"\n",
        "    \"symmetric face, looking forward\"\n",
        ")\n",
        "\n",
        "PROMPTS = {\n",
        "    \"neutral\": [\n",
        "        BASE_FACE + \", neutral expression, relaxed mouth, closed lips, no smile\",\n",
        "        BASE_FACE + \", neutral expression, calm face, closed lips, no visible teeth\",\n",
        "    ],\n",
        "    \"smiling\": [\n",
        "        BASE_FACE + \", soft smile, subtle mouth curve, no teeth, gentle expression\",\n",
        "        BASE_FACE + \", smiling, visible teeth, joyful expression, warm smile\",\n",
        "        BASE_FACE + \", medium smile, natural expression, slight teeth showing\",\n",
        "    ],\n",
        "}\n",
        "\n",
        "# images per label\n",
        "PROMPT_COUNTS = {\n",
        "    \"neutral\": 100,\n",
        "    \"smiling\": 100,\n",
        "}\n",
        "\n",
        "PROMPT_VARIANT_COUNTS = {k: len(v) for k, v in PROMPTS.items()}\n",
        "PROMPT_VARIANT_COUNTS\n"
      ],
      "metadata": {
        "id": "1cjogLDQD2dd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_generator(seed: int, device: torch.device):\n",
        "    \"\"\"\n",
        "    Create a deterministic torch.Generator on CUDA with a given seed.\n",
        "    \"\"\"\n",
        "    g = torch.Generator(device=device)\n",
        "    g.manual_seed(seed)\n",
        "    return g\n"
      ],
      "metadata": {
        "id": "Rz1PPvCYG_2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_classifier_dataset(\n",
        "    pipe,\n",
        "    out_root,\n",
        "    prompts_dict,\n",
        "    per_label_counts,\n",
        "    height=768,\n",
        "    width=768,\n",
        "    num_steps=18,\n",
        "    guidance_scale=7.0,\n",
        "    base_seed=12345,\n",
        "    device=torch.device(\"cuda\"),\n",
        "):\n",
        "    \"\"\"\n",
        "    Generate a synthetic face dataset for smile vs neutral.\n",
        "\n",
        "    - Uses ONE Stable Diffusion pipeline instance (no reloading).\n",
        "    - Saves images under:\n",
        "        out_root/neutral/\n",
        "        out_root/smiling/\n",
        "    - Returns a DataFrame with metadata for all samples.\n",
        "    \"\"\"\n",
        "    metadata_rows = []\n",
        "    global_index = 0  # used to derive seeds as base_seed + global_index\n",
        "\n",
        "    for label, prompts in prompts_dict.items():\n",
        "        n_images = per_label_counts[label]\n",
        "        n_variants = len(prompts)\n",
        "\n",
        "        label_dir = os.path.join(out_root, label)\n",
        "        os.makedirs(label_dir, exist_ok=True)\n",
        "\n",
        "        print(f\"\\nGenerating {n_images} images for label='{label}' with {n_variants} prompt variants...\")\n",
        "        for i in range(n_images):\n",
        "            variant_idx = i % n_variants         # 0-based\n",
        "            prompt_variant_idx = variant_idx + 1 # 1-based for filenames\n",
        "            prompt = prompts[variant_idx]\n",
        "\n",
        "            seed = base_seed + global_index\n",
        "            global_index += 1\n",
        "\n",
        "            generator = make_generator(seed, device)\n",
        "\n",
        "            # --- SD 3.5 generation ---\n",
        "            out = pipe(\n",
        "                prompt,\n",
        "                height=height,\n",
        "                width=width,\n",
        "                num_inference_steps=num_steps,\n",
        "                guidance_scale=guidance_scale,\n",
        "                generator=generator,\n",
        "            )\n",
        "            image = out.images[0]\n",
        "\n",
        "            # Filename encodes label, index and prompt variant index\n",
        "            fname = f\"{label}_{i:04d}_p{prompt_variant_idx}.png\"\n",
        "            fpath = os.path.join(label_dir, fname)\n",
        "            image.save(fpath)\n",
        "\n",
        "            metadata_rows.append(\n",
        "                {\n",
        "                    \"filepath\": fpath,\n",
        "                    \"label\": label,\n",
        "                    \"prompt\": prompt,\n",
        "                    \"prompt_variant_idx\": prompt_variant_idx,\n",
        "                    \"seed\": seed,\n",
        "                    \"height\": height,\n",
        "                    \"width\": width,\n",
        "                    \"num_steps\": num_steps,\n",
        "                    \"guidance_scale\": guidance_scale,\n",
        "                }\n",
        "            )\n",
        "\n",
        "            # light progress logging\n",
        "            if (i + 1) % 10 == 0 or (i + 1) == n_images:\n",
        "                print(f\"  [{label}] {i+1}/{n_images} images done...\")\n",
        "\n",
        "    df = pd.DataFrame(metadata_rows)\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "fsGZFTPcD42d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = generate_classifier_dataset(\n",
        "    pipe=pipe,\n",
        "    out_root=OUT_ROOT,\n",
        "    prompts_dict=PROMPTS,\n",
        "    per_label_counts=PROMPT_COUNTS,\n",
        "    height=HEIGHT,\n",
        "    width=WIDTH,\n",
        "    num_steps=NUM_STEPS,\n",
        "    guidance_scale=GUIDANCE_SCALE,\n",
        "    base_seed=BASE_SEED,\n",
        "    device=device,\n",
        ")\n",
        "\n",
        "df.to_csv(METADATA_PATH, index=False)\n",
        "print(\"\\n Saved metadata to:\", METADATA_PATH)\n",
        "\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "piVj6GuIHEJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_samples(df, label, n=4):\n",
        "    \"\"\"Display n random samples for a given label.\"\"\"\n",
        "    subset = df[df[\"label\"] == label]\n",
        "    n = min(n, len(subset))\n",
        "    sample = subset.sample(n, random_state=42)\n",
        "\n",
        "    fig, axes = plt.subplots(1, n, figsize=(4 * n, 4))\n",
        "    if n == 1:\n",
        "        axes = [axes]\n",
        "\n",
        "    for ax, (_, row) in zip(axes, sample.iterrows()):\n",
        "        img = Image.open(row[\"filepath\"]).convert(\"RGB\")\n",
        "        ax.imshow(img)\n",
        "        ax.set_title(f\"{label}\\n{os.path.basename(row['filepath'])}\")\n",
        "        ax.axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(\"Neutral examples:\")\n",
        "show_samples(df, \"neutral\", n=10)\n",
        "\n",
        "print(\"Smiling examples:\")\n",
        "show_samples(df, \"smiling\", n=10)\n"
      ],
      "metadata": {
        "id": "2SlQJxNiMxkC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}